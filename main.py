import whisper
import google.generativeai as genai
import os
import librosa
import noisereduce as nr
import soundfile as sf
import subprocess

# üîπ –£–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ ffmpeg (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
ffmpeg_path = r"C:\ffmpeg\bin\ffmpeg.exe"
os.environ["PATH"] += os.pathsep + os.path.dirname(ffmpeg_path)

# üîπ –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º API Gemini
genai.configure(api_key="AIzaSyArCJQTAbh1lddE1svdp3iDlKnefpdBols")

# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper
print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper...")
whisper_model = whisper.load_model("base")  # –ú–æ–∂–Ω–æ "small" –∏–ª–∏ "large"


# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ –≤ WAV
def convert_audio_to_wav(input_file):
    output_file = "converted_audio.wav"
    cmd = [
        ffmpeg_path, "-y", "-i", input_file,
        "-ac", "1", "-ar", "16000", "-sample_fmt", "s16",
        output_file
    ]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"–ê—É–¥–∏–æ {input_file} —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {output_file}")
        return output_file
    except subprocess.CalledProcessError as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        return input_file  # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞, —Ä–∞–±–æ—Ç–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º


# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è
def reduce_noise(audio_file):
    print(f"–®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è: {audio_file}")
    y, sr = librosa.load(audio_file, sr=16000)
    y_denoised = nr.reduce_noise(y=y, sr=sr)
    cleaned_file = "cleaned_" + audio_file
    sf.write(cleaned_file, y_denoised, sr)
    return cleaned_file


# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
def transcribe_audio(file_path):
    wav_file = convert_audio_to_wav(file_path)  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    clean_file = reduce_noise(wav_file)  # –£–±–∏—Ä–∞–µ–º —à—É–º
    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ: {clean_file}")
    result = whisper_model.transcribe(clean_file)
    return result["text"]


# üîπ –§—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Gemini
def analyze_text_with_gemini(text):
    prompt = (
        "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∏–∞–ª–æ–≥–æ–≤. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –µ–≥–æ —Ç–æ–Ω (positive, neutral, negative). "
        "–¢–∞–∫–∂–µ –æ—Ü–µ–Ω–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º –∏ –≤–µ–∂–ª–∏–≤–æ—Å—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä–∞. –î–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π."
        f"\n\n–¢–µ–∫—Å—Ç: {text}"
    )

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = genai.GenerativeModel("models/gemini-2.0-flash-thinking-exp-1219")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏
    response = model.generate_content([prompt])

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–∫—Å—Ç –≤ –æ—Ç–≤–µ—Ç–µ
    if hasattr(response, "text"):
        return response.text.strip()
    return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞."





def calculate_score(text):
    analysis = analyze_text_with_gemini(text)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –µ—ë —è–≤–Ω–æ)
    score = 3  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if "positive" in analysis.lower():
        score = 5
    elif "negative" in analysis.lower():
        score = 1

    return score, analysis

# üîπ –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å
def process_call(audio_file):
    text = transcribe_audio(audio_file)
    print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}")

    score, analysis = calculate_score(text)
    print(f"–ê–Ω–∞–ª–∏–∑ –æ—Ç Gemini: {analysis}")
    print(f"–ò—Ç–æ–≥–æ–≤—ã–π —Å–∫–æ—Ä-–±–∞–ª–ª: {score}/5")
    return analysis


# üîπ –¢–µ—Å—Ç–∏—Ä—É–µ–º
if __name__ == "__main__":
    process_call(audio)